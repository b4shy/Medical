{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marci/.local/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/marci/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/marci/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/marci/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/marci/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/marci/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/marci/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIHandler():\n",
    "\n",
    "    INPUT_SHAPE = (320, 320, 90)\n",
    "    LAST_CHANNEL_NO = INPUT_SHAPE[2]\n",
    "    ROTATION_PARAMS = np.array([0, 45, 90, 135, 180, 225, 270])\n",
    "\n",
    "    IMG_PATH = \"imagesTr/\"\n",
    "    LABEL_PATH = \"labelsTr/\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.epoch_counter = 0\n",
    "        self.paths_to_all_imgs = self._create_path_list(self.IMG_PATH)\n",
    "        self.paths_to_all_labels = self._create_path_list(self.LABEL_PATH)\n",
    "        self.epoch_path_list = []\n",
    "        self.batch_size = 2\n",
    "        self.classes = 2\n",
    "        \n",
    "        \n",
    "\n",
    "    def next_batch(self, batch_size=2):\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.epoch_handler()\n",
    "        \n",
    "        ind = self._pop_next_batch()\n",
    "        \n",
    "        imgs, labels = self._load_batch(ind)\n",
    "        aug_img, aug_labels = self.augment(imgs, labels)\n",
    "\n",
    "        label_mask = self._create_one_hot_label(aug_labels)\n",
    "\n",
    "        return aug_img, label_mask, aug_labels\n",
    "    \n",
    "    \n",
    "    def epoch_handler(self):\n",
    "        if len(self.epoch_path_list) < self.batch_size:\n",
    "            self._prepare_next_epoch()\n",
    "            self.epoch_counter+=1\n",
    "            print(f'Epoch: {self.epoch_counter}')\n",
    "\n",
    "    \n",
    "    def _pop_next_batch(self):\n",
    "        ind = []\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            if len(self.epoch_path_list) > 0:\n",
    "                ind.append(self.epoch_path_list.pop(0))\n",
    "        return ind\n",
    "    \n",
    "    \n",
    "    def _prepare_next_epoch(self):\n",
    "        np.random.shuffle(self.paths_to_all_imgs)\n",
    "        self.epoch_path_list = self.paths_to_all_imgs.copy()\n",
    "\n",
    "    \n",
    "\n",
    "    def augment(self, imgs, labels):\n",
    "\n",
    "        imgs = np.squeeze(imgs, -1)\n",
    "        aug_imgs = []\n",
    "        aug_labels = []\n",
    "        iaa.Sequential()\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            aug = iaa.Sequential([\n",
    "                iaa.Affine(rotate=(-90, 90), mode=\"constant\", name=\"MyAffine\"),\n",
    "                iaa.Sometimes(0.5,\n",
    "                              iaa.PiecewiseAffine(scale=(0.01, 0.05)))\n",
    "            ])\n",
    "\n",
    "            seq_imgs_deterministic = aug.to_deterministic()\n",
    "\n",
    "            aug_imgs.append(seq_imgs_deterministic.augment_image(imgs[i]))\n",
    "            aug_labels.append(seq_imgs_deterministic.augment_image(labels[i]))\n",
    "\n",
    "        return np.expand_dims(aug_imgs, -1), np.array(aug_labels)\n",
    "\n",
    "    def _load_batch(self, ind):\n",
    "        imgs = []\n",
    "        labels = []\n",
    "        for i in ind:\n",
    "            s = i.split(\"/\")\n",
    "            img = image.smooth_img(i, None).get_data()[:, :, :self.LAST_CHANNEL_NO]\n",
    "            imgs.append(img)\n",
    "\n",
    "            label_path_name = f'labelsTr/{s[1]}'\n",
    "            label = image.smooth_img(label_path_name, None).get_data()[:, :, :self.LAST_CHANNEL_NO]\n",
    "            labels.append(label)\n",
    "        return np.expand_dims(np.array(imgs), -1), np.array(labels)\n",
    "\n",
    "    def _create_one_hot_label(self, label_mask):\n",
    "        mask = np.zeros((self.batch_size, self.INPUT_SHAPE[0], self.INPUT_SHAPE[1], self.INPUT_SHAPE[2],\n",
    "                         self.classes))\n",
    "\n",
    "        for c in range(self.batch_size):\n",
    "            actual_label_mask = label_mask[c]\n",
    "            for i in range(self.classes):\n",
    "                equal = np.equal(actual_label_mask, i)\n",
    "                mask[c, :, :, :, i] = equal\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def _create_path_list(self, path):\n",
    "        return_list = []\n",
    "        for i in os.listdir(path):\n",
    "            temp_path = os.path.join(path, i)\n",
    "            return_list.append(temp_path)\n",
    "        return return_list\n",
    "\n",
    "    def load_val_data(self, val_path):\n",
    "        imgs = []\n",
    "        labels = []\n",
    "        val_path_imgs = os.path.join(val_path, \"imgs\")\n",
    "        val_path_labels = os.path.join(val_path, \"labels\")\n",
    "\n",
    "        for i in os.listdir(val_path_imgs):\n",
    "            img_path = os.path.join(val_path_imgs, i)\n",
    "            img = image.smooth_img(img_path, None).get_data()[:, :, :self.LAST_CHANNEL_NO]\n",
    "            imgs.append(img)\n",
    "\n",
    "            label_path = os.path.join(val_path_labels, i)\n",
    "            label = image.smooth_img(label_path, None).get_data()[:, :, :self.LAST_CHANNEL_NO]\n",
    "            labels.append(label)\n",
    "        return np.expand_dims(np.array(imgs), -1), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "def visualize(image, mask, original_image=None, original_mask=None):\n",
    "    fontsize = 18\n",
    "    \n",
    "    if original_image is None and original_mask is None:\n",
    "        f, ax = plt.subplots(2, 1, figsize=(8, 8))\n",
    "        plt.ion()\n",
    "        f.show()\n",
    "        f.canvas.draw()\n",
    "\n",
    "        for i in range(80):\n",
    "            ax[0].clear()\n",
    "            ax[1].clear()\n",
    "            ax[0].imshow(image[0,:,:,i,0])\n",
    "            ax[1].imshow(mask[0,:,:,i])\n",
    "            f.canvas.draw()\n",
    "            \n",
    "    else:\n",
    "        f, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "        plt.ion()\n",
    "        f.show()\n",
    "        f.canvas.draw()\n",
    "        ax[0, 0].set_title('Original image', fontsize=fontsize)\n",
    "        ax[1, 0].set_title('Original mask', fontsize=fontsize)\n",
    "        ax[0, 1].set_title('Transformed image', fontsize=fontsize)\n",
    "        ax[1, 1].set_title('Transformed mask', fontsize=fontsize)\n",
    "        for i in range(80):\n",
    "            ax[0,0].clear()\n",
    "            ax[0,1].clear()\n",
    "            ax[1,0].clear()\n",
    "            ax[1,1].clear()\n",
    "\n",
    "\n",
    "            ax[0, 0].imshow(original_image[0,:,:,i,0])\n",
    "\n",
    "            ax[1, 0].imshow(original_mask[0,:,:,i])\n",
    "\n",
    "            ax[0, 1].imshow(image[0, :,:,i, 0])\n",
    "\n",
    "            ax[1, 1].imshow(mask[0,:,:,i])\n",
    "            \n",
    "            f.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    }
   ],
   "source": [
    "dh = MRIHandler()\n",
    "aug_img1, aug_label_mask, aug_label1 = dh.next_batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_img2, aug_label_mask, aug_label2 = dh.next_batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(aug_img1, aug_label1, aug_img2, aug_label2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(img, label[:,:,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegNetBasic:\n",
    "    INPUT_SHAPE = [320, 320, 80]\n",
    "\n",
    "    def __init__(self, no_classes):\n",
    "        self.classes = no_classes\n",
    "\n",
    "    def predict(self, data, is_training):\n",
    "\n",
    "        d1 = self._decoder_block(data, 16, is_training)\n",
    "        print(d1)\n",
    "        d2 = self._decoder_block(d1, 16, is_training)\n",
    "        print(d2)\n",
    "        d3 = self._decoder_block(d2, 32, is_training)\n",
    "        print(d3)\n",
    "        d4 = self._decoder_block(d3, 32, is_training)\n",
    "        print(d4)\n",
    "\n",
    "        e1 = self._encoder_block(d4, 32, is_training)\n",
    "        e2 = self._encoder_block(e1, 16, is_training)\n",
    "        e3 = self._encoder_block(e2, 16, is_training)\n",
    "        e4 = self._encoder_block(e3, self.classes, is_training)\n",
    "\n",
    "        return e4\n",
    "\n",
    "    def loss(self, image, mask):\n",
    "        class_weight = tf.constant([0.01, 1])\n",
    "        logits = tf.multiply(image, class_weight)\n",
    "        print(logits)\n",
    "        recon_error = tf.nn.softmax_cross_entropy_with_logits(labels=mask, logits=image)\n",
    "        print(recon_error)\n",
    "\n",
    "        cost = tf.reduce_mean(recon_error)\n",
    "        return cost\n",
    "\n",
    "    def optimizer(self, lr=1e-5):\n",
    "        return tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "    def _decoder_block(self, data, no_filters, is_training):\n",
    "        l1 = tf.layers.conv3d(data, no_filters, [3, 3, 3], padding=\"same\")\n",
    "        m1 =  tf.layers.max_pooling3d(l1, [2,2,2], [2,2,2], padding=\"same\")\n",
    "        o1 = tf.nn.relu(m1)\n",
    "        return o1\n",
    "\n",
    "    def _encoder_block(self, data, no_filters, is_training):\n",
    "        u1 = tf.layers.conv3d_transpose(data, no_filters, kernel_size=[7,7,7], strides=[2,2,2], padding=\"same\")\n",
    "\n",
    "        return u1\n",
    "\n",
    "    \n",
    "\n",
    "def create_prediction_and_label(prediction):\n",
    "    values = np.argmax(prediction, axis=4)\n",
    "    values = np.expand_dims(values, 4)\n",
    "    return values\n",
    "\n",
    "\n",
    "def pixel_accuracy(prediction, mask, no_classes=2):\n",
    "    prediction = np.squeeze(prediction, axis=4)\n",
    "    sum = 0\n",
    "    target_sum = np.size(mask)\n",
    "\n",
    "    for i in range(no_classes):\n",
    "        target = (mask == i)\n",
    "        pred = (prediction == i)\n",
    "        correct_pixels = np.logical_and(target, pred)\n",
    "\n",
    "        if not np.sum(target) == 0:\n",
    "            sum += np.sum(correct_pixels) / target_sum\n",
    "\n",
    "    return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "import sys\n",
    "sys.path.append(\"../\")  # noqa\n",
    "import tensorflow as tf\n",
    "\n",
    "INPUT_SHAPE = [320, 320, 80]\n",
    "MAX_CLASS = 2\n",
    "\n",
    "logdir = \"logs/training\"\n",
    "file_writer = tf.summary.FileWriter(logdir, flush_secs=5)\n",
    "loss_feed = tf.placeholder(tf.float32)\n",
    "pixel_acc_feed = tf.placeholder(tf.float32)\n",
    "tensorboard_images = tf.placeholder(tf.float32, [None, INPUT_SHAPE[0], INPUT_SHAPE[1],INPUT_SHAPE[2], 1], name=\"Tensorboard_Images\")\n",
    "tensorboard_images_labels = tf.placeholder(tf.float32, [None, INPUT_SHAPE[0], INPUT_SHAPE[1],INPUT_SHAPE[2], 1], name=\"Tensorboard_Images_Labels\")\n",
    "tensorboard_inputs = tf.placeholder(tf.float32, [None, INPUT_SHAPE[0], INPUT_SHAPE[1],INPUT_SHAPE[2], 3], name=\"Inputs\")\n",
    "loss_summary = tf.summary.scalar(\"Loss\", loss_feed)\n",
    "pixel_acc_summary = tf.summary.scalar(\"Pixel_Acc\", pixel_acc_feed)\n",
    "img_summary = tf.summary.image(\"Predictions\", tensorboard_images)\n",
    "img_summary2 = tf.summary.image(\"Images\", tensorboard_inputs)\n",
    "img_summary3 = tf.summary.image(\"Labels\", tensorboard_images_labels)\n",
    "\n",
    "\n",
    "input_im = tf.placeholder(dtype=tf.float32, shape=[None, INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2], 1], name=\"input\")\n",
    "mask = tf.placeholder(dtype=tf.float32, shape=[None, INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2], MAX_CLASS], name=\"Segmentation\")\n",
    "\n",
    "\n",
    "segnet = SegNetBasic(2)\n",
    "prediction = segnet.predict(input_im, is_training=True)\n",
    "cost = segnet.loss(prediction, mask)\n",
    "optimizer = segnet.optimizer(1e-5)\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_op = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=30)\n",
    "\n",
    "\n",
    "dh = MRIHandler()\n",
    "STEP = 3000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, f'checkpoints/model-{STEP}')\n",
    "    for i in range(STEP, 6000):\n",
    "\n",
    "        img_batch, label_batch, orig_labels = dh.next_batch(1)\n",
    "        _, loss, pred = sess.run([train_op, cost, prediction], feed_dict={input_im: img_batch, mask: label_batch})\n",
    "        print(loss)\n",
    "\n",
    "        predicted_segmentation = create_prediction_and_label(pred)\n",
    "        pixel_acc = pixel_accuracy(predicted_segmentation, orig_labels, MAX_CLASS)\n",
    "        print(pixel_acc)\n",
    "\n",
    "        if i % 10 != 0:\n",
    "            summaries = [loss_summary, pixel_acc_summary]\n",
    "            summary_op = tf.summary.merge(summaries)\n",
    "            summary = sess.run(summary_op, feed_dict={loss_feed: loss,\n",
    "                                                      pixel_acc_feed: pixel_acc})\n",
    "\n",
    "            file_writer.add_summary(summary, i)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            \n",
    "            img, label = dh.load_val_data(\"val/\")\n",
    "            pred = sess.run(prediction, feed_dict={input_im: np.expand_dims(img[0],0)})\n",
    "            pred = create_prediction_and_label(pred)\n",
    "            pred_sum = np.sum(pred)\n",
    "            print(f'Ones in Pred:{pred_sum}')\n",
    "            \n",
    "            pixel_acc = pixel_accuracy(pred, label, MAX_CLASS)\n",
    "            print(f'Val Pixel Acc:{pixel_acc}')\n",
    "\n",
    "\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            saver.save(sess, \"checkpoints/model\", global_step=i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "STEP = 3800\n",
    "IMG_NO = 0\n",
    "INPUT_SHAPE = [320, 320, 80]\n",
    "input_im = tf.placeholder(dtype=tf.float32, shape=[None, INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2], 1], name=\"input\")\n",
    "\n",
    "segnet = SegNetBasic(2)\n",
    "prediction = segnet.predict(input_im, False)\n",
    "saver = tf.train.Saver()\n",
    "dh = MRIHandler()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "    saver.restore(sess, f'checkpoints/model-{STEP}')\n",
    "    img, label = dh.load_val_data(\"val/\")\n",
    "    #img, _, label = dh.next_batch(1)\n",
    "    pred = sess.run(prediction, feed_dict={input_im: np.expand_dims(img[IMG_NO],0)})\n",
    "    pred = create_prediction_and_label(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax2 = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "test_pred = pred*10\n",
    "pred2 = np.ma.masked_where(test_pred == 0, test_pred)\n",
    "orig = np.ma.masked_where(label == 0, label)\n",
    "\n",
    "for i in range(80):\n",
    "    ax.clear()\n",
    "    ax.imshow(img[0,:,:,i,0])\n",
    "    \n",
    "    ax.imshow(pred2[0,:,:,i,0], alpha=1, cmap=\"Reds\")\n",
    "    ax.imshow(orig[IMG_NO,:,:,i], alpha=0.5)\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "for i in range(80):\n",
    "    ax.clear()\n",
    "    ax.imshow(img[1,:,:,i,0])\n",
    "    orig = np.ma.masked_where(label == 0, label)\n",
    "    ax.imshow(orig[0,:,:,i], alpha=0.7, cmap=\"Reds\")\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy(prediction, mask, no_classes=2):\n",
    "    prediction = np.squeeze(prediction, axis=4)\n",
    "    sum = 0\n",
    "    target_sum = np.sum((mask > 0))\n",
    "\n",
    "    for i in range(1, no_classes):\n",
    "        target = (mask == i)\n",
    "        pred = (prediction == i)\n",
    "        correct_pixels = np.logical_and(target, pred)\n",
    "\n",
    "        if not np.sum(target) == 0:\n",
    "            sum += np.sum(correct_pixels) / target_sum\n",
    "\n",
    "    return sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array([[0, 1, 1], \n",
    "                [1, 1, 1]])\n",
    "pred = pred.reshape(1, 2, 3, 1, 1)\n",
    "mask = np.array([[1, 1, 1], \n",
    "                [1, 1, 1]])\n",
    "mask = mask.reshape(1, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_accuracy(pred, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(pred, axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from imgaug.augmenters import HorizontalFlip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = MRIHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = MRIHandler()\n",
    "img, label, orig = dh.next_batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "def visualize(image, mask, original_image=None, original_mask=None):\n",
    "    fontsize = 18\n",
    "    \n",
    "    if original_image is None and original_mask is None:\n",
    "        f, ax = plt.subplots(2, 1, figsize=(8, 8))\n",
    "\n",
    "        ax[0].imshow(image[0,:,:,50,0])\n",
    "        ax[1].imshow(mask[0,:,:,50])\n",
    "    else:\n",
    "        f, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "        plt.ion()\n",
    "        f.show()\n",
    "        f.canvas.draw()\n",
    "        ax[0, 0].set_title('Original image', fontsize=fontsize)\n",
    "        ax[1, 0].set_title('Original mask', fontsize=fontsize)\n",
    "        ax[0, 1].set_title('Transformed image', fontsize=fontsize)\n",
    "        ax[1, 1].set_title('Transformed mask', fontsize=fontsize)\n",
    "        for i in range(80):\n",
    "            ax[0,0].clear()\n",
    "            ax[0,1].clear()\n",
    "            ax[1,0].clear()\n",
    "            ax[1,1].clear()\n",
    "\n",
    "\n",
    "            ax[0, 0].imshow(original_image[0,:,:,i,0])\n",
    "\n",
    "            ax[1, 0].imshow(original_mask[0,:,:,i])\n",
    "\n",
    "            ax[0, 1].imshow(image[0, :,:,i, 0])\n",
    "\n",
    "            ax[1, 1].imshow(mask[0,:,:,i])\n",
    "            \n",
    "            f.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %matplotlib notebook\n",
    "    def augment(imgs, labels):\n",
    "\n",
    "        imgs = np.squeeze(imgs, -1)\n",
    "        aug_imgs = []\n",
    "        aug_labels = []\n",
    "        iaa.Sequential()\n",
    "\n",
    "        for i in range(1):\n",
    "            print(i)\n",
    "            aug = iaa.Sequential([\n",
    "                iaa.Affine(rotate=(-90, 90), mode=\"constant\", name=\"MyAffine\"),\n",
    "                iaa.PiecewiseAffine(scale=(0.01, 0.05))\n",
    "            ])\n",
    "\n",
    "            \n",
    "            seq_imgs_deterministic = aug.to_deterministic()\n",
    "\n",
    "            aug_imgs.append(seq_imgs_deterministic.augment_image(imgs[i]))\n",
    "            aug_labels.append(seq_imgs_deterministic.augment_image(labels[i]))\n",
    "\n",
    "        return np.expand_dims(aug_imgs, -1), np.array(aug_labels), np.expand_dims(imgs, -1), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels, orig_labels, unaug_img, unaug_labels =  dh.next_batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_imgs, aug_labels, orig, orig_labels = augment(unaug_img, unaug_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize(aug_imgs, aug_labels, original_image=unaug_img, original_mask=unaug_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
